{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2716645,"sourceType":"datasetVersion","datasetId":1655371},{"sourceId":240881,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":205822,"modelId":227572}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Defining directories\nimage_dirs = [\"/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test/Images/glaucoma\", \"/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test/Images/normal\"]  # List of image directories\nmask_dir = \"/kaggle/input/drishtigs-retina-dataset-for-onh-segmentation/Test-20211018T060000Z-001/Test/Test_GT\"  # Mask directory\n\n# Define image dimensions\nimg_height, img_width, img_channels = 256, 256, 1\nbatch_size = 8\n\ndef load_images_and_masks(image_dirs, mask_dir):\n    images, masks = [], []\n\n    # Iterate through both image directories\n    for image_dir in image_dirs:\n        for filename in os.listdir(image_dir):\n            # Load image\n            img_path = os.path.join(image_dir, filename)\n            img = load_img(img_path, color_mode=\"grayscale\", target_size=(img_height, img_width)) #Load image as  grayscale to match model input\n            img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]\n            images.append(img_array)\n\n            # Load corresponding mask\n            mask_filename = filename.split('.')[0] + \"_ODsegSoftmap.png\"\n            mask_path = os.path.join(mask_dir, filename.split('.')[0], \"SoftMap\", mask_filename)\n            if not os.path.exists(mask_path):\n                print(f\"Mask not found for {filename} at {mask_path}. Skipping...\")\n                continue\n            mask = load_img(mask_path, color_mode=\"grayscale\", target_size=(img_height, img_width))\n            mask_array = img_to_array(mask) / 255.0  # Normalize to [0, 1]\n\n            # Convert mask to binary inverted mask\n            mask_binary = np.where(mask_array > 0.5, 0, 1).astype(np.float32)  # Invert: black becomes white, and vice versa\n            masks.append(mask_binary)\n\n    return np.array(images), np.array(masks)\n\n# Load images and masks\nimages, masks = load_images_and_masks(image_dirs, mask_dir)\n\n# Convert to TensorFlow tensors\nimages_tensor = tf.convert_to_tensor(images, dtype=tf.float32)\nmasks_tensor = tf.convert_to_tensor(masks, dtype=tf.float32)\n\n# Create TensorFlow dataset\ndataset = tf.data.Dataset.from_tensor_slices((images_tensor, masks_tensor))\ndataset = dataset.batch(batch_size).shuffle(buffer_size=len(images))\n\n# Print dataset shapes for verification\nfor batch_images, batch_masks in dataset.take(1):\n    print(\"Batch Images Shape:\", batch_images.shape) \n    print(\"Batch Masks Shape:\", batch_masks.shape)   ","metadata":{"_uuid":"1e3e6517-62fc-4586-9c7b-cdf945521c59","_cell_guid":"428bc171-d9a5-4ace-9353-b2a1d22ccaff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-29T13:57:42.383856Z","iopub.execute_input":"2025-01-29T13:57:42.384176Z","iopub.status.idle":"2025-01-29T13:58:10.512850Z","shell.execute_reply.started":"2025-01-29T13:57:42.384151Z","shell.execute_reply":"2025-01-29T13:58:10.511688Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define metrics and loss functions as custom model features\n@tf.keras.utils.register_keras_serializable()\ndef weighted_binary_crossentropy(y_true, y_pred):\n    weights = tf.where(tf.less(tf.range(tf.shape(y_true)[2]), tf.shape(y_true)[2] // 2), 2.0, 1.0)\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = bce * weights\n    return tf.reduce_mean(weighted_bce)\n\n@tf.keras.utils.register_keras_serializable()\ndef dice_coefficient(y_true, y_pred):\n    # Cast both y_true and y_pred to float32 to ensure compatibility\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n    \n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + 1e-6) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-6)\n    \n    return dice\n\n@tf.keras.utils.register_keras_serializable()\ndef iou(y_true, y_pred):\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    iou_metric = (intersection ) / (union )\n    return iou_metric","metadata":{"_uuid":"180fa9ad-bb5d-45e3-956f-938c31c844a2","_cell_guid":"c56afa10-8c0d-4cd0-9792-ce4e3da44ed3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-29T13:58:10.524791Z","iopub.execute_input":"2025-01-29T13:58:10.525210Z","iopub.status.idle":"2025-01-29T13:58:10.547031Z","shell.execute_reply.started":"2025-01-29T13:58:10.525177Z","shell.execute_reply":"2025-01-29T13:58:10.546025Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load the saved XNet model\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model('/kaggle/input/best_models/keras/default/1/Best Models/xnet.keras')","metadata":{"_uuid":"f9f4fa66-59ce-42ab-96e5-812b9ac272c0","_cell_guid":"e4f92a99-62f7-4f0a-a8f8-a83f4b2e8325","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-29T13:58:10.548278Z","iopub.execute_input":"2025-01-29T13:58:10.548570Z","iopub.status.idle":"2025-01-29T13:58:13.352829Z","shell.execute_reply.started":"2025-01-29T13:58:10.548543Z","shell.execute_reply":"2025-01-29T13:58:13.351857Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluate the model \nmodel.evaluate(dataset)","metadata":{"_uuid":"381808d7-d270-4dcc-97a2-e8f943368874","_cell_guid":"87a1bbdc-6795-4dd1-b9aa-de4296f55fef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-29T13:58:13.353830Z","iopub.execute_input":"2025-01-29T13:58:13.354086Z","iopub.status.idle":"2025-01-29T13:59:21.094665Z","shell.execute_reply.started":"2025-01-29T13:58:13.354064Z","shell.execute_reply":"2025-01-29T13:59:21.093638Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plotting predictions against the image and ground truth\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\n\n\n# Take one batch of data\nbatch = next(iter(dataset.take(1)))  # Get one batch\nimages, masks = batch  # Unpack images and ground truth masks\n\n# Make predictions on the batch\npredictions = model.predict(images)\n\n\nbatch_size = images.shape[0]  # Number of samples in the batch\n\nfor i in range(batch_size):\n    plt.figure(figsize=(12, 4))\n\n    # Plot original image\n    plt.subplot(1, 3, 1)\n    plt.imshow(tf.squeeze(images[i]), cmap=\"gray\")\n    plt.title(\"Original Image\")\n    plt.axis(\"off\")\n\n    # Plot ground truth mask\n    plt.subplot(1, 3, 2)\n    plt.imshow(tf.squeeze(masks[i]), cmap=\"gray\")\n    plt.title(\"Ground Truth Mask\")\n    plt.axis(\"off\")\n\n    # Plot predicted mask\n    plt.subplot(1, 3, 3)\n    plt.imshow(tf.squeeze(predictions[i] > 0.5), cmap=\"gray\")  # Apply threshold if binary segmentation\n    plt.title(\"Predicted Mask\")\n    plt.axis(\"off\")\n\n    plt.show()","metadata":{"_uuid":"42c5a2a6-d9c6-4ce9-bcdd-5bae82fddd66","_cell_guid":"c94314d4-7579-4588-9afd-b1b35723ae49","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-29T13:59:21.095648Z","iopub.execute_input":"2025-01-29T13:59:21.095966Z","iopub.status.idle":"2025-01-29T13:59:35.080558Z","shell.execute_reply.started":"2025-01-29T13:59:21.095941Z","shell.execute_reply":"2025-01-29T13:59:35.079508Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}