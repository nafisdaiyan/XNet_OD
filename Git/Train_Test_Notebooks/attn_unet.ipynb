{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.image import random_crop\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "image_folder1 = '/kaggle/input/palm-center/Center/Mid/Images'\n",
    "mask_folder1 = '/kaggle/input/palm-center/Center/Mid/Masks'\n",
    "\n",
    "image_folder2 = '/kaggle/input/palm-center/Center/Fovea/Images'\n",
    "mask_folder2 = '/kaggle/input/palm-center/Center/Fovea/Masks'\n",
    "\n",
    "image_folder3 = '/kaggle/input/palm-center/Center/OD/Images'\n",
    "mask_folder3 = '/kaggle/input/palm-center/Center/OD/Masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image and mask files from each directory\n",
    "image_files1 = set(os.listdir(image_folder1))\n",
    "mask_files1 = set(os.listdir(mask_folder1))\n",
    "\n",
    "image_files2 = set(os.listdir(image_folder2))\n",
    "mask_files2 = set(os.listdir(mask_folder2))\n",
    "\n",
    "image_files3 = set(os.listdir(image_folder3))\n",
    "mask_files3 = set(os.listdir(mask_folder3))\n",
    "\n",
    "# Combine the files from all directories\n",
    "image_files = image_files1.union(image_files2).union(image_files3)\n",
    "mask_files = mask_files1.union(mask_files2).union(mask_files3)\n",
    "\n",
    "print(f\"Total images: {len(image_files)}\")\n",
    "print(f\"Total masks: {len(mask_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size=(256,256)):\n",
    "    return cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "def preprocess_image_mask(image_path, mask_path):\n",
    "    # Load the grayscale image and mask\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)    \n",
    "\n",
    "    # Resize image and mask to 512x512\n",
    "    image_resized = resize_image(image).reshape(256,256, 1)\n",
    "    mask_resized = resize_image(mask).reshape(256,256, 1)\n",
    "\n",
    "    # Make the mask binary\n",
    "    _, mask_binary = cv2.threshold(mask_resized, 127, 255, cv2.THRESH_BINARY)\n",
    "    return image_resized, mask_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folders = [image_folder1, image_folder2, image_folder3]\n",
    "mask_folders = [mask_folder1, mask_folder2, mask_folder3]\n",
    "centre_labels = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks, label_list = [], [], []\n",
    "\n",
    "for image_folder, mask_folder, label in zip(image_folders, mask_folders, centre_labels):\n",
    "    for img_name in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        mask_path = os.path.join(mask_folder, img_name)\n",
    "\n",
    "    # Preprocess and resize\n",
    "        image_resized, mask_binary = preprocess_image_mask(img_path, mask_path)\n",
    "        images.append(image_resized)\n",
    "        masks.append(mask_binary)\n",
    "\n",
    "   \n",
    "    #Append the label\n",
    "        label_list.append(label)\n",
    "        \n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "labels = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average size of the masks for each label\n",
    "\n",
    "average_mask_sizes = {}\n",
    "  # Total pixels in a 256x256 image\n",
    "for label in np.unique(labels):\n",
    "    label_masks = masks[labels == label]\n",
    "    # Count the black pixels (mask area) in each mask and average\n",
    "    average_mask_size = np.mean(np.sum(label_masks == 0, axis=(1, 2)))\n",
    "    average_mask_sizes[label] = average_mask_size\n",
    "\n",
    "print(\"Average Mask Sizes per Label:\")\n",
    "for label, size in average_mask_sizes.items():\n",
    "    print(f\"Label {label}: {size:.2f} pixels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_temp, y_train, y_temp,  label_train, label_temp = train_test_split(\n",
    "    images, masks,labels, test_size=0.2, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test,  label_val, label_test = train_test_split(\n",
    "    X_temp, y_temp, label_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 256,256, 1)\n",
    "y_val = y_val.reshape(-1, 256,256, 1)\n",
    "y_test = y_test.reshape(-1,256,256, 1)\n",
    "\n",
    "print('y_train shape', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = label_train.reshape(-1,1)\n",
    "label_val = label_val.reshape(-1,1)\n",
    "label_test = label_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a tensorflow dataset\n",
    "\n",
    "\n",
    "# Convert arrays to TensorFlow tensors\n",
    "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "label_train_tensor = tf.convert_to_tensor(label_train, dtype=tf.float32)\n",
    "\n",
    "# Create TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor,  y_train_tensor))\n",
    "\n",
    "# Batch the dataset (adjust batch size as needed)\n",
    "batch_size = 8\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for validation and testing sets\n",
    "X_val_tensor = tf.convert_to_tensor(X_val, dtype=tf.float32)\n",
    "y_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.float32)\n",
    "label_val_tensor = tf.convert_to_tensor(label_val, dtype=tf.float32)\n",
    "\n",
    "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "label_test_tensor = tf.convert_to_tensor(label_test, dtype=tf.float32)\n",
    "\n",
    "# Validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_tensor,y_val_tensor))\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Test dataset\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_tensor, y_test_tensor))\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data\n",
    "def normalize_data(image, mask):\n",
    "       \n",
    "    # Normalize image to [0, 1] by dividing by 255\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Normalize mask to [0, 1] and round to binary\n",
    "    mask = mask / 255.0\n",
    "    mask = tf.cast(tf.round(mask), tf.float32)\n",
    "    \n",
    "    return image, mask  # Return the image,and the normalized mask\n",
    "\n",
    "\n",
    "# Apply normalization to train, validation, and test datasets\n",
    "train_dataset = train_dataset.map(normalize_data)\n",
    "val_dataset = val_dataset.map(normalize_data)\n",
    "test_dataset = test_dataset.map(normalize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create filtered subsets of test dataset based on image centres\n",
    "\n",
    "# Get indices based on labels\n",
    "label_0_indices = np.where(label_test == 0)[0]\n",
    "label_1_indices = np.where(label_test == 1)[0]\n",
    "label_2_indices = np.where(label_test == 2)[0]\n",
    "\n",
    "# Extract images and masks with specified labels\n",
    "X_test_label_0 = X_test[label_0_indices]\n",
    "y_test_label_0 = y_test[label_0_indices]\n",
    "X_test_label_1 = X_test[label_1_indices]\n",
    "y_test_label_1 = y_test[label_1_indices]\n",
    "X_test_label_2 = X_test[label_2_indices]\n",
    "y_test_label_2 = y_test[label_2_indices]\n",
    "\n",
    "# Convert to tensors \n",
    "X_test_label_0_tensor = tf.convert_to_tensor(X_test_label_0, dtype=tf.float32)\n",
    "y_test_label_0_tensor = tf.convert_to_tensor(y_test_label_0, dtype=tf.float32)\n",
    "X_test_label_1_tensor = tf.convert_to_tensor(X_test_label_1, dtype=tf.float32)\n",
    "y_test_label_1_tensor = tf.convert_to_tensor(y_test_label_1, dtype=tf.float32)\n",
    "X_test_label_2_tensor = tf.convert_to_tensor(X_test_label_2, dtype=tf.float32)\n",
    "y_test_label_2_tensor = tf.convert_to_tensor(y_test_label_2, dtype=tf.float32)\n",
    "\n",
    "# Create filtered subsets \n",
    "test_dataset_mid = tf.data.Dataset.from_tensor_slices((X_test_label_0_tensor, y_test_label_0_tensor))\n",
    "test_dataset_mid = test_dataset_mid.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset_fovea = tf.data.Dataset.from_tensor_slices((X_test_label_1_tensor, y_test_label_1_tensor))\n",
    "test_dataset_fovea = test_dataset_fovea.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset_od = tf.data.Dataset.from_tensor_slices((X_test_label_2_tensor, y_test_label_2_tensor))\n",
    "test_dataset_od = test_dataset_od.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset_mid = test_dataset_mid.map(normalize_data)\n",
    "test_dataset_fovea = test_dataset_fovea.map(normalize_data)\n",
    "test_dataset_od = test_dataset_od.map(normalize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define metrics and loss function\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    weights = tf.where(tf.less(tf.range(tf.shape(y_true)[2]), tf.shape(y_true)[2] // 2), 2.0, 1.0)\n",
    "    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    weighted_bce = bce * weights\n",
    "    return tf.reduce_mean(weighted_bce)\n",
    "\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    # Cast both y_true and y_pred to float32 to ensure compatibility\n",
    "    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n",
    "    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n",
    "    \n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + 1e-6) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-6)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n",
    "    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n",
    "\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
    "    iou_metric = (intersection ) / (union )\n",
    "    return iou_metric\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Attention UNet\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Layer, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Multiply, Add, Reshape, Activation\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (256, 256, 1)\n",
    "\n",
    "\n",
    "# Define Custom Spatial Attention Layer\n",
    "class SpatialAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SpatialAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = Conv2D(2, (3, 3), activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "        self.avg_pool = GlobalAveragePooling2D(keepdims=True)\n",
    "        self.max_pool = GlobalMaxPooling2D(keepdims=True)\n",
    "        self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_pool = self.avg_pool(inputs)\n",
    "        max_pool = self.max_pool(inputs)\n",
    "        concat = self.concat([avg_pool, max_pool])\n",
    "        conv = self.conv1(concat)\n",
    "        conv = self.conv2(conv)\n",
    "        return Multiply()([inputs, conv])\n",
    "\n",
    "# Define Spatial Attention module using the custom layer\n",
    "def spatial_attention(input):\n",
    "    return SpatialAttention()(input)\n",
    "\n",
    "# Define input layer\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "# Contracting Path with Spatial Attention\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "conv1_attention = spatial_attention(conv1)  # Apply Spatial Attention\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_attention)\n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "conv2_attention = spatial_attention(conv2)  # Apply Spatial Attention\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_attention)\n",
    "\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "conv3_attention = spatial_attention(conv3)  # Apply Spatial Attention\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3_attention)\n",
    "\n",
    "# Bottleneck\n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "# Expansive Path\n",
    "up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "merge5 = concatenate([conv3_attention, up5], axis=3)\n",
    "conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge5)\n",
    "conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "merge6 = concatenate([conv2_attention, up6], axis=3)\n",
    "conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge6)\n",
    "conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "merge7 = concatenate([conv1_attention, up7], axis=3)\n",
    "conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge7)\n",
    "conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "# Output Layer\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "learning_rates = [1e-4, 0.5e-4]\n",
    "\n",
    "predictions_dict = {}\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=[\"LR\", \"Dice\", \"IoU\", \"F_Dice\", \"F_IoU\",\"M_Dice\", \"M_IoU\",\"O_Dice\", \"O_IoU\",\"Epochs\"])\n",
    "\n",
    "# Training loop\n",
    "for lr in learning_rates:\n",
    "    \n",
    "    # Initialize the model\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=optimizer, loss=weighted_binary_crossentropy, metrics=[dice_coefficient, iou])\n",
    "\n",
    "    # Callbacks\n",
    "    model_name = f\"Attn_UNet_lr{lr}.keras\"\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=os.path.join(\"saved_models\", model_name),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_weights_only=False\n",
    "    )\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=200,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=1,\n",
    "        batch_size=8,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_metrics_combined = model.evaluate(test_dataset, verbose=0)\n",
    "    dice_coeff, iou_score = val_metrics_combined[1], val_metrics_combined[2]\n",
    "\n",
    "    val_metrics_fovea = model.evaluate(test_dataset_fovea, verbose=0)\n",
    "    dice_coeff_f, iou_score_f = val_metrics_fovea[1], val_metrics_fovea[2]\n",
    "\n",
    "    val_metrics_mid = model.evaluate(test_dataset_mid, verbose=0)\n",
    "    dice_coeff_m, iou_score_m = val_metrics_mid[1], val_metrics_mid[2]\n",
    "\n",
    "    val_metrics_od = model.evaluate(test_dataset_od, verbose=0)\n",
    "    dice_coeff_o, iou_score_o = val_metrics_od[1], val_metrics_od[2]\n",
    "\n",
    "    # Add results to DataFrame\n",
    "    new_row = {\n",
    "        \"LR\": lr,\n",
    "        \"Dice\": dice_coeff,\n",
    "        \"IoU\": iou_score,\n",
    "        \"F_Dice\": dice_coeff_f,\n",
    "        \"F_IoU\": iou_score_f,\n",
    "        \"M_Dice\": dice_coeff_m,\n",
    "        \"M_IoU\": iou_score_m,\n",
    "        \"O_Dice\": dice_coeff_o,\n",
    "        \"O_IoU\": iou_score_o,\n",
    "        \"Epochs\": len(history.history['loss'])\n",
    "    }\n",
    "\n",
    "    new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index= True)\n",
    "\n",
    "    predictions = model.predict(test_dataset)\n",
    "    predictions_dict[model_name] = predictions\n",
    "\n",
    "# Display the full DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test datasets and corresponding labels\n",
    "test_datasets = {\n",
    "    \"Fovea\": test_dataset_fovea,\n",
    "    \"Mid\": test_dataset_mid,\n",
    "    \"OD\": test_dataset_od\n",
    "}\n",
    "\n",
    "num_models = len(predictions_dict)\n",
    "\n",
    "# Loop through each dataset\n",
    "for dataset_name, dataset in test_datasets.items():\n",
    "    # Unpack the dataset\n",
    "    test_batch = next(iter(dataset.take(1)))  # Take one batch\n",
    "    test_images = test_batch[0]\n",
    "    test_masks  = test_batch[1]\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    test_images = test_images.numpy()\n",
    "    \n",
    "    test_masks = test_masks.numpy()\n",
    "    \n",
    "    # Create a figure for visualization\n",
    "    fig, axes = plt.subplots(5, num_models + 2, figsize=(15, 25))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    # Loop through the first 5 test images\n",
    "    for row in range(min(5, len(test_images))):\n",
    "        # Plot the original image\n",
    "        axes[row, 0].imshow(test_images[row][..., 0], cmap=\"gray\")\n",
    "        axes[row, 0].set_title(\"Image\")\n",
    "        axes[row, 0].axis(\"off\")\n",
    "\n",
    "        # Plot the true mask\n",
    "        axes[row, 1].imshow(test_masks[row], cmap=\"gray\")\n",
    "        axes[row, 1].set_title(\"True Mask\")\n",
    "        axes[row, 1].axis(\"off\")\n",
    "\n",
    "        # Plot the predictions for each model\n",
    "        for col, (model_name, predictions) in enumerate(predictions_dict.items()):\n",
    "            predicted_mask = (predictions[row].squeeze() > 0.3).astype(int)\n",
    "            ax = axes[row, col + 2]\n",
    "            ax.imshow(predicted_mask, cmap=\"gray\")\n",
    "            ax.set_title(f'Model {model_name}')\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Set the figure title based on the dataset name\n",
    "    fig.suptitle(f'{dataset_name} Dataset Predictions')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6025226,
     "sourceId": 9834897,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30827,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
