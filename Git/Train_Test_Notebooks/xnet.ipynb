{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9834897,"sourceType":"datasetVersion","datasetId":6025226}],"dockerImageVersionId":30827,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.image import random_crop\nfrom PIL import Image\nimport cv2\nimport random\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the directories\nimage_folder1 = '/kaggle/input/palm-center/Center/Mid/Images'\nmask_folder1 = '/kaggle/input/palm-center/Center/Mid/Masks'\n\nimage_folder2 = '/kaggle/input/palm-center/Center/Fovea/Images'\nmask_folder2 = '/kaggle/input/palm-center/Center/Fovea/Masks'\n\nimage_folder3 = '/kaggle/input/palm-center/Center/OD/Images'\nmask_folder3 = '/kaggle/input/palm-center/Center/OD/Masks'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the image and mask files from each directory\nimage_files1 = set(os.listdir(image_folder1))\nmask_files1 = set(os.listdir(mask_folder1))\n\nimage_files2 = set(os.listdir(image_folder2))\nmask_files2 = set(os.listdir(mask_folder2))\n\nimage_files3 = set(os.listdir(image_folder3))\nmask_files3 = set(os.listdir(mask_folder3))\n\n# Combine the files from all directories\nimage_files = image_files1.union(image_files2).union(image_files3)\nmask_files = mask_files1.union(mask_files2).union(mask_files3)\n\nprint(f\"Total images: {len(image_files)}\")\nprint(f\"Total masks: {len(mask_files)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resize_image(img, size=(256,256)):\n    return cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n\ndef preprocess_image_mask(image_path, mask_path):\n    # Load the grayscale image and mask\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  \n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)    \n\n    # Resize image and mask to 512x512\n    image_resized = resize_image(image).reshape(256,256, 1)\n    mask_resized = resize_image(mask).reshape(256,256, 1)\n\n    # Make the mask binary\n    _, mask_binary = cv2.threshold(mask_resized, 127, 255, cv2.THRESH_BINARY)\n    return image_resized, mask_binary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_folders = [image_folder1, image_folder2, image_folder3]\nmask_folders = [mask_folder1, mask_folder2, mask_folder3]\ncentre_labels = [0,1,2]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, masks, label_list = [], [], []\n\nfor image_folder, mask_folder, label in zip(image_folders, mask_folders, centre_labels):\n    for img_name in os.listdir(image_folder):\n        img_path = os.path.join(image_folder, img_name)\n        mask_path = os.path.join(mask_folder, img_name)\n\n    # Preprocess and resize\n        image_resized, mask_binary = preprocess_image_mask(img_path, mask_path)\n        images.append(image_resized)\n        masks.append(mask_binary)\n\n   \n    #Append the label\n        label_list.append(label)\n        \nimages = np.array(images)\nmasks = np.array(masks)\nlabels = np.array(label_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the average size of the masks for each label\n\naverage_mask_sizes = {}\n  # Total pixels in a 256x256 image\nfor label in np.unique(labels):\n    label_masks = masks[labels == label]\n    # Count the black pixels (mask area) in each mask and average\n    average_mask_size = np.mean(np.sum(label_masks == 0, axis=(1, 2)))\n    average_mask_sizes[label] = average_mask_size\n\nprint(\"Average Mask Sizes per Label:\")\nfor label, size in average_mask_sizes.items():\n    print(f\"Label {label}: {size:.2f} pixels\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data\nX_train, X_temp, y_train, y_temp,  label_train, label_temp = train_test_split(\n    images, masks,labels, test_size=0.2, random_state=42\n)\nX_val, X_test, y_val, y_test,  label_val, label_test = train_test_split(\n    X_temp, y_temp, label_temp, test_size=0.5, random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train = y_train.reshape(-1, 256,256, 1)\ny_val = y_val.reshape(-1, 256,256, 1)\ny_test = y_test.reshape(-1,256,256, 1)\n\nprint('y_train shape', y_train.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_train = label_train.reshape(-1,1)\nlabel_val = label_val.reshape(-1,1)\nlabel_test = label_test.reshape(-1,1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a tensorflow dataset\n\n\n# Convert arrays to TensorFlow tensors\nX_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\ny_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\nlabel_train_tensor = tf.convert_to_tensor(label_train, dtype=tf.float32)\n\n# Create TensorFlow Dataset\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor,  y_train_tensor))\n\n# Batch the dataset (adjust batch size as needed)\nbatch_size = 8\ntrain_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Repeat for validation and testing sets\nX_val_tensor = tf.convert_to_tensor(X_val, dtype=tf.float32)\ny_val_tensor = tf.convert_to_tensor(y_val, dtype=tf.float32)\nlabel_val_tensor = tf.convert_to_tensor(label_val, dtype=tf.float32)\n\nX_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\ny_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)\nlabel_test_tensor = tf.convert_to_tensor(label_test, dtype=tf.float32)\n\n# Validation dataset\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val_tensor,y_val_tensor))\nval_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n# Test dataset\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test_tensor, y_test_tensor))\ntest_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Normalize data\ndef normalize_data(image, mask):\n       \n    # Normalize image to [0, 1] by dividing by 255\n    image = image / 255.0\n    \n    # Normalize mask to [0, 1] and round to binary\n    mask = mask / 255.0\n    mask = tf.cast(tf.round(mask), tf.float32)\n    \n    return image, mask  # Return the image,and the normalized mask\n\n\n# Apply normalization to train, validation, and test datasets\ntrain_dataset = train_dataset.map(normalize_data)\nval_dataset = val_dataset.map(normalize_data)\ntest_dataset = test_dataset.map(normalize_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Create filtered subsets of test dataset based on image centres\n\n# Get indices based on labels\nlabel_0_indices = np.where(label_test == 0)[0]\nlabel_1_indices = np.where(label_test == 1)[0]\nlabel_2_indices = np.where(label_test == 2)[0]\n\n# Extract images and masks with specified labels\nX_test_label_0 = X_test[label_0_indices]\ny_test_label_0 = y_test[label_0_indices]\nX_test_label_1 = X_test[label_1_indices]\ny_test_label_1 = y_test[label_1_indices]\nX_test_label_2 = X_test[label_2_indices]\ny_test_label_2 = y_test[label_2_indices]\n\n# Convert to tensors \nX_test_label_0_tensor = tf.convert_to_tensor(X_test_label_0, dtype=tf.float32)\ny_test_label_0_tensor = tf.convert_to_tensor(y_test_label_0, dtype=tf.float32)\nX_test_label_1_tensor = tf.convert_to_tensor(X_test_label_1, dtype=tf.float32)\ny_test_label_1_tensor = tf.convert_to_tensor(y_test_label_1, dtype=tf.float32)\nX_test_label_2_tensor = tf.convert_to_tensor(X_test_label_2, dtype=tf.float32)\ny_test_label_2_tensor = tf.convert_to_tensor(y_test_label_2, dtype=tf.float32)\n\n# Create filtered subsets \ntest_dataset_mid = tf.data.Dataset.from_tensor_slices((X_test_label_0_tensor, y_test_label_0_tensor))\ntest_dataset_mid = test_dataset_mid.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\ntest_dataset_fovea = tf.data.Dataset.from_tensor_slices((X_test_label_1_tensor, y_test_label_1_tensor))\ntest_dataset_fovea = test_dataset_fovea.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\ntest_dataset_od = tf.data.Dataset.from_tensor_slices((X_test_label_2_tensor, y_test_label_2_tensor))\ntest_dataset_od = test_dataset_od.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\ntest_dataset_mid = test_dataset_mid.map(normalize_data)\ntest_dataset_fovea = test_dataset_fovea.map(normalize_data)\ntest_dataset_od = test_dataset_od.map(normalize_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Define metrics and loss function\n\ndef weighted_binary_crossentropy(y_true, y_pred):\n    weights = tf.where(tf.less(tf.range(tf.shape(y_true)[2]), tf.shape(y_true)[2] // 2), 2.0, 1.0)\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = bce * weights\n    return tf.reduce_mean(weighted_bce)\n\n\ndef dice_coefficient(y_true, y_pred):\n    # Cast both y_true and y_pred to float32 to ensure compatibility\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n    \n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + 1e-6) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-6)\n    \n    return dice\n\ndef iou(y_true, y_pred):\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    iou_metric = (intersection ) / (union )\n    return iou_metric\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Concatenate, Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, Activation\nfrom tensorflow.keras.optimizers import Adam\n\ndef model(input_shape=(256, 256, 1), kernel_size=3, filter_depth=(64, 128, 256, 512)):\n    \n    img_input = Input(shape=input_shape)\n    \n    # Encoder\n    conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = Activation(\"relu\")(batch1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n    # 128x128\n    \n    conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = Activation(\"relu\")(batch2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n    # 64x64\n    \n    conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = Activation(\"relu\")(batch3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n    # 32x32\n    \n    conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = Activation(\"relu\")(batch4)\n    # 32x32\n    \n    conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = Activation(\"relu\")(batch5)\n    # 32x32\n    \n    # Up\n    up6 = UpSampling2D(size=(2, 2))(act5)\n    conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\n    batch6 = BatchNormalization()(conv6)\n    act6 = Activation(\"relu\")(batch6)\n    concat6 = Concatenate()([act3, act6])\n    # 64x64\n    \n    up7 = UpSampling2D(size=(2, 2))(concat6)\n    conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\n    batch7 = BatchNormalization()(conv7)\n    act7 = Activation(\"relu\")(batch7)\n    concat7 = Concatenate()([act2, act7])\n    # 128x128\n    \n    # Down\n    conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = Activation(\"relu\")(batch8)\n    pool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n    # 64x64\n    \n    conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = Activation(\"relu\")(batch9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n    # 32x32\n    \n    # Flat\n    conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = Activation(\"relu\")(batch10)\n    # 32x32\n    \n    conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = Activation(\"relu\")(batch11)\n    # 32x32\n    \n    # Up\n    up12 = UpSampling2D(size=(2, 2))(act11)\n    conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\n    batch12 = BatchNormalization()(conv12)\n    act12 = Activation(\"relu\")(batch12)\n    concat12 = Concatenate()([act9, act12])\n    # 64x64\n    \n    up13 = UpSampling2D(size=(2, 2))(concat12)\n    conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\n    batch13 = BatchNormalization()(conv13)\n    act13 = Activation(\"relu\")(batch13)\n    concat13 = Concatenate()([act8, act13])\n    # 128x128\n    \n    up14 = UpSampling2D(size=(2, 2))(concat13)\n    conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\n    batch14 = BatchNormalization()(conv14)\n    act14 = Activation(\"relu\")(batch14)\n    concat14 = Concatenate()([act1, act14])\n    # 256x256\n    \n    conv15 = Conv2D(1, (1, 1), padding=\"valid\", activation=\"sigmoid\")(concat14)\n    \n    \n    model = Model(img_input, conv15)\n    \n    return model\n\n# Example usage\nmodel = model()\n\nprint(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nlearning_rates = [1e-4, 0.5e-4]\n\npredictions_dict = {}\n\n# Initialize a DataFrame to store the results\nresults_df = pd.DataFrame(columns=[ \"LR\", \"Dice\", \"IoU\", \"F_Dice\", \"F_IoU\",\"M_Dice\", \"M_IoU\",\"O_Dice\", \"O_IoU\",\"Epochs\"])\n\n# Training loop\nfor lr in learning_rates:   \n\n    # Compile the model\n    optimizer = Adam(learning_rate=lr)\n    model.compile(optimizer=optimizer, loss=weighted_binary_crossentropy, metrics=[dice_coefficient, iou])\n    # Callbacks\n    model_name = f\"XNet_lr{lr}.keras\"\n    checkpoint_callback = ModelCheckpoint(\n        filepath=os.path.join(\"saved_models\", model_name),\n        monitor='val_loss',\n            save_best_only=True,\n            verbose=1,\n            save_weights_only=False\n        )\n    early_stopping_callback = EarlyStopping(\n        monitor='val_loss',\n        patience=20,\n        restore_best_weights=True,\n        verbose=1\n        )\n    # Train the model\n    history = model.fit(\n        train_dataset,\n        validation_data=val_dataset,\n        epochs=1,\n        batch_size=8,\n        callbacks=[checkpoint_callback, early_stopping_callback],\n        verbose=1\n        )\n\n        # Evaluate the model\n    val_metrics_combined = model.evaluate(test_dataset, verbose=0)\n    dice_coeff, iou_score = val_metrics_combined[1], val_metrics_combined[2]\n    val_metrics_fovea = model.evaluate(test_dataset_fovea, verbose=0)\n    dice_coeff_f, iou_score_f = val_metrics_fovea[1], val_metrics_fovea[2]\n\n    val_metrics_mid = model.evaluate(test_dataset_mid, verbose=0)\n    dice_coeff_m, iou_score_m = val_metrics_mid[1], val_metrics_mid[2]\n\n    val_metrics_od = model.evaluate(test_dataset_od, verbose=0)\n    dice_coeff_o, iou_score_o = val_metrics_od[1], val_metrics_od[2]\n        \n        # Add results to DataFrame\n    new_row = {\n        \"LR\": lr,\n        \"Dice\": dice_coeff,\n        \"IoU\": iou_score,\n        \"F_Dice\": dice_coeff_f,\n        \"F_IoU\": iou_score_f,\n        \"M_Dice\": dice_coeff_m,\n        \"M_IoU\": iou_score_m,\n        \"O_Dice\": dice_coeff_o,\n        \"O_IoU\": iou_score_o,\n        \"Epochs\": len(history.history['loss'])\n        }\n\n    new_row_df = pd.DataFrame([new_row])\n\n    results_df = pd.concat([results_df, new_row_df], ignore_index= True)\n    predictions = model.predict(test_dataset)\n    predictions_dict[model_name] = predictions\n\n# Display the full DataFrame\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.max_rows', None)\n\nprint(results_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the test datasets and corresponding labels\ntest_datasets = {\n    \"Fovea\": test_dataset_fovea,\n    \"Mid\": test_dataset_mid,\n    \"OD\": test_dataset_od\n}\n\nnum_models = len(predictions_dict)\n\n# Loop through each dataset\nfor dataset_name, dataset in test_datasets.items():\n    # Unpack the dataset\n    test_batch = next(iter(dataset.take(1)))  # Take one batch\n    test_images = test_batch[0]\n    test_masks  = test_batch[1]\n\n    # Convert tensors to numpy arrays\n    test_images = test_images.numpy()\n    \n    test_masks = test_masks.numpy()\n    \n    # Create a figure for visualization\n    fig, axes = plt.subplots(5, num_models + 2, figsize=(15, 25))\n    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n\n    # Loop through the first 5 test images\n    for row in range(min(5, len(test_images))):\n        # Plot the original image\n        axes[row, 0].imshow(test_images[row][..., 0], cmap=\"gray\")\n        axes[row, 0].set_title(\"Image\")\n        axes[row, 0].axis(\"off\")\n\n        # Plot the true mask\n        axes[row, 1].imshow(test_masks[row], cmap=\"gray\")\n        axes[row, 1].set_title(\"True Mask\")\n        axes[row, 1].axis(\"off\")\n\n        # Plot the predictions for each model\n        for col, (model_name, predictions) in enumerate(predictions_dict.items()):\n            predicted_mask = (predictions[row].squeeze() > 0.3).astype(int)\n            ax = axes[row, col + 2]\n            ax.imshow(predicted_mask, cmap=\"gray\")\n            ax.set_title(f'Model {model_name}')\n            ax.axis(\"off\")\n\n    # Set the figure title based on the dataset name\n    fig.suptitle(f'{dataset_name} Dataset Predictions')\n\n    # Show the plot\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}