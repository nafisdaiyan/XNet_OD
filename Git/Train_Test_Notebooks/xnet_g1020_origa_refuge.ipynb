{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3863247,"sourceType":"datasetVersion","datasetId":2296461},{"sourceId":10584181,"sourceType":"datasetVersion","datasetId":6549992},{"sourceId":240881,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":205822,"modelId":227572}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.image import random_crop\nfrom PIL import Image\nimport cv2\nimport random\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"1c0f1f09-55fa-4a2e-b36b-e828b9dd46b4","_cell_guid":"af2d62b2-583a-4a4a-a444-c96269ea2b3d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:27:48.070752Z","iopub.execute_input":"2025-01-25T18:27:48.071264Z","iopub.status.idle":"2025-01-25T18:28:06.931591Z","shell.execute_reply.started":"2025-01-25T18:27:48.071233Z","shell.execute_reply":"2025-01-25T18:28:06.930299Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define datasets and corresponding folders\ndatasets = {\n    \"refuge\": {\n        \"image_folder\": \"/kaggle/input/glaucoma-datasets/REFUGE/test/Images\",\n        \"mask_folder\": \"/kaggle/input/glaucoma-datasets/REFUGE/test/Masks\",\n        \"output_image_folder\": \"/kaggle/working/refuge_images\",\n        \"output_mask_folder\": \"/kaggle/working/refuge_masks\"\n    },\n    \"origa\": {\n        \"image_folder\": \"/kaggle/input/glaucoma-datasets/ORIGA/Images_Square\",\n        \"mask_folder\": \"/kaggle/input/glaucoma-datasets/ORIGA/Masks_Square\",\n        \"output_image_folder\": \"/kaggle/working/origa_images\",\n        \"output_mask_folder\": \"/kaggle/working/origa_masks\"\n    },\n    \"g1020\": {\n        \"image_folder\": \"/kaggle/input/glaucoma-datasets/G1020/Images_Square\",\n        \"mask_folder\": \"/kaggle/input/glaucoma-datasets/G1020/Masks_Square\",\n        \"output_image_folder\": \"/kaggle/working/g1020_images\",\n        \"output_mask_folder\": \"/kaggle/working/g1020_masks\"\n    }\n}\n\n# Iterate over each dataset\nfor dataset_name, paths in datasets.items():\n    image_folder = paths[\"image_folder\"]\n    mask_folder = paths[\"mask_folder\"]\n    output_image_folder = paths[\"output_image_folder\"]\n    output_mask_folder = paths[\"output_mask_folder\"]\n\n    # Create output directories if they do not exist\n    os.makedirs(output_image_folder, exist_ok=True)\n    os.makedirs(output_mask_folder, exist_ok=True)\n\n    # Process all images in the image folder\n    image_files = os.listdir(image_folder)\n\n    for img_name in image_files:\n        if img_name.endswith('.jpg') or img_name.endswith('.png'):  # Check for image file extensions\n            img_path = os.path.join(image_folder, img_name)\n            \n            # Convert the image to grayscale\n            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            if image is not None:\n                # Save the grayscale image as PNG\n                grayscale_img_path = os.path.join(output_image_folder, img_name.replace('.jpg', '.png').replace('.png', '.png'))\n                cv2.imwrite(grayscale_img_path, image)\n            \n            # Find the corresponding mask\n            mask_name = img_name.replace('.jpg', '.png')\n            mask_path = os.path.join(mask_folder, mask_name)\n\n            # Process and invert the mask colors (black to white, everything else to black)\n            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n            if mask is not None:\n                mask = np.where(mask == 0, 255, 0)  # Invert the colors: black -> white, everything else -> black\n                \n                # Save the processed mask as PNG\n                processed_mask_path = os.path.join(output_mask_folder, mask_name)\n                cv2.imwrite(processed_mask_path, mask)\n\n    print(f\"Processing and saving complete for dataset: {dataset_name}\")\n\nprint(\"Processing and saving complete.\")","metadata":{"_uuid":"24cc19a9-e836-457a-a963-d7b3f81ed1eb","_cell_guid":"80cc417e-6a6a-4995-a054-9011a1a078b7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:28:06.932919Z","iopub.execute_input":"2025-01-25T18:28:06.933793Z","iopub.status.idle":"2025-01-25T18:29:19.730236Z","shell.execute_reply.started":"2025-01-25T18:28:06.933749Z","shell.execute_reply":"2025-01-25T18:29:19.728996Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Resize and normalize parameters\nIMG_SIZE = (256, 256) \nBATCH_SIZE = 8        \n\n\n# Define the function for loading and preprocessing \ndef load_and_preprocess_image(image_path):\n    # Load the image in grayscale\n    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    # Resize the image\n    image_resized = cv2.resize(image, IMG_SIZE)\n    # Normalize the image\n    image_normalized = image_resized / 255.0  # Normalize to [0, 1]\n    # Add channel dimension (256, 256, 1)\n    return np.expand_dims(image_normalized, axis=-1)\n    \ndef load_and_preprocess_mask(mask_path):\n    # Load the mask in grayscale\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    # Resize the mask\n    mask_resized = cv2.resize(mask, IMG_SIZE)\n    # Normalize the mask (binary mask)\n    mask_normalized = mask_resized / 255.0  # Normalize to [0, 1]\n    # Add channel dimension (256, 256, 1)\n    return np.expand_dims(mask_normalized, axis=-1)\n      \n\n# Folders for the three pairs of images and masks\nfolders = {\n    \"refuge\": {\n        \"image_folder\": \"/kaggle/working/refuge_images\",\n        \"mask_folder\": \"/kaggle/working/refuge_masks\"\n    },\n    \"origa\": {\n        \"image_folder\": \"/kaggle/working/origa_images\",\n        \"mask_folder\": \"/kaggle/working/origa_masks\"\n    },\n    \"g1020\": {\n        \"image_folder\": \"/kaggle/working/g1020_images\",\n        \"mask_folder\": \"/kaggle/working/g1020_masks\"\n    }\n}\n\n\n# Iterate through each dataset\ndatasets = {}\nfor dataset_name, paths in folders.items():\n    image_folder = paths[\"image_folder\"]\n    mask_folder = paths[\"mask_folder\"]\n\n    images = []\n    masks = []\n\n    # Iterate through image and mask files\n    image_files = os.listdir(image_folder)\n    for img_name in image_files:\n        if img_name.endswith('.png'):  # Check for image file extensions\n            img_path = os.path.join(image_folder, img_name)\n            mask_name = img_name.replace('.png', '.png')  # Ensure mask name matches\n            msk_path = os.path.join(mask_folder, mask_name)\n\n            # Load and process the image and mask\n            image = load_and_preprocess_image(img_path)\n            mask = load_and_preprocess_mask(msk_path)\n\n            # Append the processed image and mask\n            images.append(image)\n            masks.append(mask)\n\n    # Convert lists to numpy arrays\n    images = np.array(images)\n    masks = np.array(masks)\n\n    #Convert the arrays to tensors\n    image_tensor = tf.convert_to_tensor(images, dtype=tf.float32)\n    mask_tensor = tf.convert_to_tensor(masks, dtype=tf.float32)\n    # Create a TensorFlow dataset from the images and masks\n    dataset = tf.data.Dataset.from_tensor_slices((image_tensor, mask_tensor))\n\n    # Shuffle and batch the dataset\n    dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)\n\n    # Store the dataset\n    datasets[dataset_name] = dataset\n\n# Now you can access the datasets like this:\nrefuge_dataset = datasets[\"refuge\"]\noriga_dataset = datasets[\"origa\"]\ng1020_dataset = datasets[\"g1020\"]\n\n\nprint(\"Dataset created and ready for training.\")","metadata":{"_uuid":"8e4573d7-8152-439b-9a11-2b6b8dc2f343","_cell_guid":"79997bcb-5e75-4cbe-8b51-88f1ae150ce3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:29:19.731241Z","iopub.execute_input":"2025-01-25T18:29:19.731659Z","iopub.status.idle":"2025-01-25T18:29:47.019295Z","shell.execute_reply.started":"2025-01-25T18:29:19.731617Z","shell.execute_reply":"2025-01-25T18:29:47.018098Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load metrics and loss function as custom parameters\n@tf.keras.utils.register_keras_serializable()\ndef weighted_binary_crossentropy(y_true, y_pred):\n    weights = tf.where(tf.less(tf.range(tf.shape(y_true)[2]), tf.shape(y_true)[2] // 2), 2.0, 1.0)\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    weighted_bce = bce * weights\n    return tf.reduce_mean(weighted_bce)\n\n@tf.keras.utils.register_keras_serializable()\ndef dice_coefficient(y_true, y_pred):\n    # Cast both y_true and y_pred to float32 to ensure compatibility\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n    \n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    dice = (2. * intersection + 1e-6) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1e-6)\n    \n    return dice\n\n@tf.keras.utils.register_keras_serializable()\ndef iou(y_true, y_pred):\n    y_true_f = tf.keras.backend.flatten(tf.cast(y_true, tf.float32))\n    y_pred_f = tf.keras.backend.flatten(tf.cast(y_pred, tf.float32))\n\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n    iou_metric = (intersection ) / (union )\n    return iou_metric","metadata":{"_uuid":"37088355-00ff-4e18-b24f-2258b4007e11","_cell_guid":"2189e9d6-3ece-4410-8f59-4b37d2c20a16","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Load the model\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model('/kaggle/input/best_models/keras/default/1/Best Models/xnet.keras')","metadata":{"_uuid":"1c944a94-fdb9-4343-a734-2d51fd18ce4d","_cell_guid":"701ad063-f01e-4505-ba53-6352ea05ac7f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-26T10:00:56.680068Z","iopub.execute_input":"2025-01-26T10:00:56.680569Z","iopub.status.idle":"2025-01-26T10:00:59.491353Z","shell.execute_reply.started":"2025-01-26T10:00:56.680523Z","shell.execute_reply":"2025-01-26T10:00:59.490403Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluate on REFUGE\nmodel.evaluate(refuge_dataset)","metadata":{"_uuid":"ad390c2e-fa63-4380-a46b-40f9286aa9d7","_cell_guid":"9af1e1d5-8351-4aa8-b1b0-211f2dc33f11","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:29:50.171253Z","iopub.execute_input":"2025-01-25T18:29:50.171664Z","iopub.status.idle":"2025-01-25T18:37:35.001798Z","shell.execute_reply.started":"2025-01-25T18:29:50.171624Z","shell.execute_reply":"2025-01-25T18:37:35.000832Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluate on random 400 images on ORIGA\nmodel.evaluate(origa_dataset.take(50))","metadata":{"_uuid":"a4f0f85c-93c6-4cec-8624-a5c4f8b846d9","_cell_guid":"8be3c6d7-9e13-4a31-87b4-4920fa52b57c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:49:34.863116Z","iopub.execute_input":"2025-01-25T18:49:34.863532Z","iopub.status.idle":"2025-01-25T18:57:02.074404Z","shell.execute_reply.started":"2025-01-25T18:49:34.863505Z","shell.execute_reply":"2025-01-25T18:57:02.073203Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluate on random 400 images on G1020\nmodel.evaluate(g1020_dataset.take(50))","metadata":{"_uuid":"111e68c9-e10c-4be6-94a3-4c8066544c65","_cell_guid":"9eee50c2-a55b-4b67-88f3-df6f2ba1fb53","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-01-25T18:57:42.777972Z","iopub.execute_input":"2025-01-25T18:57:42.778435Z","iopub.status.idle":"2025-01-25T19:05:08.327398Z","shell.execute_reply.started":"2025-01-25T18:57:42.778401Z","shell.execute_reply":"2025-01-25T19:05:08.325998Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}